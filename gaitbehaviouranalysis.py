# -*- coding: utf-8 -*-
"""GaitBehaviourAnalysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DcraTJNT3WXhEnnj7pSqB5vfhb6lhtzb
"""

# from sklearn.model_selection import train_test_split

# # Split the dataset into training and testing sets (80% train, 20% test)
# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

# # Save the training and testing sets as CSV files
# train_df.to_csv('train_dataset.csv', index=False)
# test_df.to_csv('test_dataset.csv', index=False)

# # Show the number of rows in each dataset
# print(f'Training set: {train_df.shape[0]} rows')
# print(f'Test set: {test_df.shape[0]} rows')

import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Load the training and testing datasets
train_df = pd.read_csv('train_dataset.csv')
test_df = pd.read_csv('test_dataset.csv')

# Split features (X) and labels (y) from the training and test datasets
X_train = train_df.drop(columns='label')
y_train = train_df['label']
X_test = test_df.drop(columns='label')
y_test = test_df['label']

# Initialize the classifier (RandomForestClassifier)
model = RandomForestClassifier(n_estimators=5, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Evaluate the model performance
accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

# Print the results
print("Accuracy:", accuracy)
print("Precision:", precision)
print("Recall:", recall)
print("F1 Score:", f1)

# Print detailed classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

import cv2
import os

# Create a directory to save the frames
output_dir = '/content/drive/MyDrive/BTP/extracted_8'
os.makedirs(output_dir, exist_ok=True)

# Open the video file
video_path = '/content/drive/MyDrive/BTP/8sec.mp4'  # Replace with your video path
cap = cv2.VideoCapture(video_path)

frame_count = 0
success = True

while success:
    # Read a frame from the video
    success, frame = cap.read()

    if success:
        # Save the frame as an image
        cv2.imwrite(f"{output_dir}/frame_{frame_count:04d}.jpg", frame)
        frame_count += 1

# Release the video capture object
cap.release()
print(f"Extracted {frame_count} frames.")

!pip install mediapipe

import cv2
import mediapipe as mp
from google.colab.patches import cv2_imshow  # Import the function for image display

mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

# Directory containing extracted frames
output_dir = '/content/drive/MyDrive/BTP/extracted'

# Process each frame
for frame_path in os.listdir(output_dir):
    frame = cv2.imread(os.path.join(output_dir, frame_path))
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(frame_rgb)

    # Draw the pose landmarks on the frame
    if result.pose_landmarks:
        mp_drawing.draw_landmarks(frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)

    # the frame with landmarks are displayed
    cv2_imshow(frame)  # Using cv2_imshow instead of cv2.imshow
    cv2.waitKey(0)

cv2.destroyAllWindows()

import cv2
import mediapipe as mp
import numpy as np
from google.colab.patches import cv2_imshow  # For displaying images in Google Colab

mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

output_dir = '/content/drive/MyDrive/BTP/extracted'  # Directory containing extracted frames

all_keypoints = []  # List to store keypoints for all frames

# MediaPipe foot indices
LEFT_FOOT_INDEX = mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value
RIGHT_FOOT_INDEX = mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value

# Process each frame
for frame_path in os.listdir(output_dir):
    frame = cv2.imread(os.path.join(output_dir, frame_path))
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(frame_rgb)

    # Extract keypoints if detected
    if result.pose_landmarks:
        keypoints = []
        for landmark in result.pose_landmarks.landmark:
            # Append (x, y) coordinates of each landmark
            keypoints.append((landmark.x, landmark.y))
        all_keypoints.append(keypoints)  # Store keypoints of the frame

        # Draw the pose landmarks on the frame
        mp_drawing.draw_landmarks(frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Display the frame with landmarks
        cv2_imshow(frame)

# Calculate movement of specific keypoints (e.g., left and right foot)
left_foot_movements = []
right_foot_movements = []

if len(all_keypoints) > 1:  # Ensure there are at least two frames
    for i in range(1, len(all_keypoints)):
        # Get left foot keypoint coordinates for consecutive frames
        kp_prev_left = np.array(all_keypoints[i-1][LEFT_FOOT_INDEX])  # Previous frame
        kp_curr_left = np.array(all_keypoints[i][LEFT_FOOT_INDEX])    # Current frame

        # Get right foot keypoint coordinates for consecutive frames
        kp_prev_right = np.array(all_keypoints[i-1][RIGHT_FOOT_INDEX])  # Previous frame
        kp_curr_right = np.array(all_keypoints[i][RIGHT_FOOT_INDEX])    # Current frame

        # Calculate Euclidean distance for left foot movement
        movement_left = np.linalg.norm(kp_curr_left - kp_prev_left)
        left_foot_movements.append(movement_left)

        # Calculate Euclidean distance for right foot movement
        movement_right = np.linalg.norm(kp_curr_right - kp_prev_right)
        right_foot_movements.append(movement_right)

    print("Movement of the left foot keypoint between frames:", left_foot_movements)
    print("Movement of the right foot keypoint between frames:", right_foot_movements)
else:
    print("Not enough frames to calculate movements.")

import matplotlib.pyplot as plt

# Sample data
left_foot_movements = [3.655009112260814e-06, 0.0007135501285973842, 0.0010587087357922798, 0.0011378546031209653, 0.003498033244486471, 0.0044177256097811006, 0.0020141881641375326, 0.000738652243784467, 0.0017467507583054005, 0.0020474486137687597, 0.0012774500511224104, 0.0008990770931696973, 0.0010609111914036573, 0.0010922771145243247, 0.001643227721875308, 0.0022979480470327676, 0.008103854645839993, 0.0036149534133168783, 0.006925256743568496, 0.006522486130806536, 0.0070694164934968435, 0.010616601582792637, 0.010494009451838995, 0.007280603449109638, 0.008176975782572347, 0.007079825179483111, 0.0023047102104813586, 0.0017360460105493168, 0.0020666404945085233, 0.005412733572115541, 0.0072465570775157384, 0.004440193199879687, 0.0007706730209454946, 0.0005497230020135838, 0.0013815506186591264, 0.0011675460322593258, 0.0006915752459205154, 0.0003015974529106244, 0.0007529447881748859, 0.0023207910976533112, 0.002494495959390138, 0.0022648781944593715, 0.002707605148117121, 0.0005161154153481937, 0.0018397469655844242, 0.0015979707863572764, 0.0013020537618478587, 0.0010905112303726228, 0.0011294156134585786, 0.00019357342824023223, 0.0005319181719526875, 0.00010232675130970792, 0.00023717192642513398, 0.0021728790717426157, 0.007594514286596359, 0.009674567655772374, 0.005899806496982302, 0.007036032938667391, 0.008806564080102282, 0.010246176215445735, 0.011347340641733051, 0.011368077684964006, 0.007397150028231334, 0.01133246034978509, 0.009341747296773858, 0.00047858183632725436, 0.0028140576807068798, 0.00519799570617656, 0.009881973704670094, 0.006874630643223166, 0.0027302333857919373, 0.0011454972822573955, 0.0018450469093315859, 0.001397567331537326, 0.0001275419208398947, 0.0006632706582203642, 0.0010425992980353026, 0.00013820652771054563, 0.0006118027761339469, 0.05884199037647181, 0.03192286626506406, 0.015848913930193918, 0.009101350643965493, 0.0005514092155873324, 0.0012534336063201239, 0.002115696168847878, 0.00029407159636563653, 0.0011836311779240317, 0.0005566285025660676, 0.00022308778201244489, 0.0004703724438251245, 0.0032510703693715095, 0.01013395385312202, 0.013681596892455059, 0.011214231121043534, 0.010840812358114483, 0.016445596312498104, 0.014809586638506884, 0.014302420732644285, 0.0108615012113335, 0.011832975978843313, 0.01260903213670772, 0.004872104418694387, 0.002067867768167042, 0.01705263146789857, 0.008666303312627799, 0.004514814612164823, 0.0020594024148589255, 0.0015592398730445236, 0.002096090324413517, 0.001869671453357733, 0.0013894559673169927, 0.000169122224232355, 0.0022003336308115276, 0.0006355232516437126, 0.005748883902293872, 0.00511195367915191, 0.0039363731333270455, 0.004625380483171777, 0.0014274003889346801, 0.0007371324131574901, 0.0006041205622945448, 0.0003014880545637351, 0.0006528266438855878, 0.0010895589377887226, 0.0012577047384537338, 0.0004728920775231782, 0.0018318443614663887, 0.01066864330457163, 0.019304911902682926, 0.015507464572962218, 0.013730744511752832, 0.018606671611279532, 0.020124487510393255, 0.0176062520909291, 0.016299361268713765, 0.01614182213218175, 0.01919015071434801, 0.010442039150113814, 0.0030639888148696515, 0.015772571907038256, 0.013057984738694023, 0.005165466426659494, 0.0019228497759086413, 0.005063624894411654, 0.005377877411053023, 0.011406968892320348, 0.005221650139931637, 0.009918181458438301, 0.0023186079310836384, 0.008625463330955938, 0.006454149117020269, 0.0009055331331607493, 0.01597229850755162, 0.003569124009442162, 0.0023791469173734285, 0.0009839016707574502, 0.00108888991437616, 0.0007931399353854873, 0.0009562363575823143, 0.0036935059034988358, 0.0005343365752281092, 0.0026007128604706954, 0.005932804546186995, 0.013290229548626947, 0.01961084567350373, 0.02262726045678757, 0.0163063512665004, 0.024531226318255137, 0.026100784718061952, 0.02894041045142897, 0.019192874956477788, 0.010115519926887234, 0.01947568322969302, 0.018292500904809005, 0.013967389502673429, 0.008229282141588955, 0.010333799802783445, 0.01076768563996775, 0.003205731411062909, 0.002030980677407385, 0.011411442800080496, 0.01362970733198415, 0.005175925397741131, 0.011166752765510579, 0.030355513592560106, 0.0068320931004477, 0.021493133056444284, 0.010762568988348549, 0.006293936727763241, 0.0028434226765043794, 0.0015693477015613258, 0.0015448811240613045, 0.004726778917925956, 0.0037627714319220665, 0.001576811820704993, 0.005729071700902119, 0.010821353384601067, 0.009613580136404521, 0.02033271316760849, 0.025298205595933917, 0.010732031227382447, 0.06749545185520164, 0.044012280884232015, 0.021953802747273148, 0.012070616098620403, 0.037384372485250325, 0.03331606641590612, 0.007871684223853995, 0.045881909171745984]  # Complete data here
right_foot_movements = [0.003953920124041378, 0.008238613992107855, 0.0027929513491273903, 0.009408125504119484, 0.0037964060653655515, 0.0030845277712283747, 0.008085915374340535, 0.002939788224991284, 0.005135329800402712, 0.003512633326321724, 0.009209696048189839, 0.001583595016693448, 0.0009232635331798783, 0.0013435708951036861, 0.0004712369134109517, 0.0015042612497922396, 0.0007021815642871077, 0.00043203198149956113, 0.0006387988933342264, 0.0021026117806040097, 0.0002757574298622715, 0.000673213591718868, 0.0014519324623252692, 0.00021237727594527233, 0.001076756983298031, 0.0011465051962684593, 0.0010817626266305237, 0.00017392714051294234, 0.0006411305983737309, 0.0007225252324339965, 0.0008790264814274177, 0.0018438768392482383, 0.0010029437469162095, 0.00010638110445755061, 0.0021980929727895273, 0.0037993753271541716, 0.004566792530843076, 0.005601443107293403, 0.007282323792033144, 0.006381625427919715, 0.009242981519848726, 0.0073179342151074205, 0.0044854246883349455, 0.004630214311078471, 0.005125626484268529, 0.009234841298004967, 0.007076817220422203, 0.0053256299311005995, 0.0037434502710752006, 0.0038291261267857472, 0.004410868213340668, 0.0019439090808090695, 0.0023600406381124508, 0.0012693893449584818, 0.002430968793652358, 0.001458212092128393, 0.0009601500140365394, 0.0005467615157631894, 0.006127012441736206, 0.0023993670156819153, 0.0009919948173368208, 0.0008958925147395355, 0.00024446255032005264, 0.0006392475106982484, 0.0013566067877584123, 0.0005275726817017606, 7.00168128254923e-05, 0.0002808319266956762, 0.0013629161401377714, 0.0010195003490644859, 0.0011126747320576887, 0.000619239470427563, 0.0010248845092312175, 0.004598701200183604, 0.004708638731578287, 0.006703392729350338, 0.00842142369190797, 0.01047318548070933, 0.014097726051335229, 0.007971626357511872, 0.005820005811649434, 0.011592603850334879, 0.013357333052283963, 0.009820998772924553, 0.004257996016586318, 0.0050902657702919536, 0.013670295815414513, 0.006513379613791573, 0.006167159638380606, 0.0019059074077195923, 0.0018598245543517242, 0.001469472702143874, 0.0035611217569789253, 0.0012051977021625255, 0.00120306699237643, 0.0033037247207689906, 0.0029187932666194225, 0.0009162218552114268, 0.0015663778536463473, 0.0008695828341188074, 0.00040774597907459694, 0.0002995261339638755, 0.00015616035866274053, 0.0005172412643590239, 0.0013617827905194205, 0.0012117747083028577, 0.0012165400223426808, 0.0016885691098393449, 0.0018635531853824, 0.0056114759937396326, 0.008276779725869569, 0.0086789818246199, 0.008325867592649503, 0.014115137984451515, 0.02221101484624843, 0.0064866983715990536, 0.011620715506717347, 0.020160209253959893, 0.01764862665754276, 0.013585408583973257, 0.003088582772221796, 0.004137654777342234, 0.01835188429400705, 0.011199778341845596, 0.00555458815575851, 0.0007800510575865716, 0.0013805640342367616, 0.0011851261083720781, 0.0030269914932627576, 0.004218907380889057, 0.0022681042233818442, 0.0014535194223295404, 0.005360586138895407, 0.006301505370922634, 0.0007182276520504679, 0.0011046913990012013, 0.0008520752635541456, 0.0004818050312415429, 0.0002986330528371805, 0.00023470163519716874, 0.0007486114191879518, 0.002136908226033706, 0.003207566740276528, 0.0003184328150791834, 0.0023481877544677316, 0.0049989640660537855, 0.0133065702261311, 0.013348162009739508, 0.01545530229929501, 0.017169321621828083, 0.020168615449679204, 0.008612830276829417, 0.015166659064505103, 0.029508625992824365, 0.021023411488518114, 0.02274110708995826, 0.011248195384938557, 0.004030389127106712, 0.017851867873644747, 0.004985246448139803, 0.013666693133915839, 0.01627459099673757, 0.009969645996706415, 0.01075156064322186, 0.004251918631742494, 0.0010786352824931464, 0.009413308654210943, 0.0030122174477656524, 0.00891229201443275, 0.004115768388209869, 0.003911565142118351, 0.0004191548477158561, 0.0032932659671504553, 0.0013036576385636082, 0.006088893072239618, 0.0012268184026283035, 0.0004787941352228039, 0.0006199453974072221, 0.0040530620967583015, 0.008691268555752484, 0.009306591309293193, 0.01066901966036676, 0.013284689874894062, 0.015039591989049786, 0.032342194540030844, 0.02772385832019081, 0.03707254118717271, 0.02258159767475211, 0.032790328785308014, 0.0358725337547802, 0.022203440765636386, 0.011221573474403083, 0.012483427633158541, 0.03037749120142676, 0.010513548957611602, 0.007476816664690237, 0.012222051369916692, 0.0386560580063224, 0.011226380917785302, 0.005756542787831195, 0.007284748192157424, 0.019137301742221512, 0.014492793467854521, 0.01645982419540105, 0.015090778801095352, 0.0017586443398121207, 0.007009500391829587, 0.02125071256988692, 0.04807786751057182, 0.06309830275326185] # Complete data here

# Plot the movement data
plt.figure(figsize=(14, 7))
plt.plot(left_foot_movements, label='Left Foot Movement', color='blue')
plt.plot(right_foot_movements, label='Right Foot Movement', color='red')
plt.xlabel('Frame Number')
plt.ylabel('Movement Magnitude')
plt.title('Movement of Left and Right Foot Keypoints Between Frames')
plt.legend()
plt.show()

import numpy as np

# Calculate statistical features
def calculate_features(movements):
    return {
        'mean': np.mean(movements),
        'std': np.std(movements),
        'max': np.max(movements),
        'min': np.min(movements),
        'median': np.median(movements)
    }

left_foot_features = calculate_features(left_foot_movements)
right_foot_features = calculate_features(right_foot_movements)

print("Left Foot Features:", left_foot_features)
print("Right Foot Features:", right_foot_features)

"""## both legs and hands"""

import cv2
import mediapipe as mp
import numpy as np
import os
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow  # For displaying images in Google Colab

# Initialize MediaPipe pose model
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

output_dir = '/content/drive/MyDrive/BTP/extracted'  # Directory containing extracted frames

all_keypoints = []  # List to store keypoints for all frames

# MediaPipe keypoint indices for feet and hands
LEFT_FOOT_INDEX = mp_pose.PoseLandmark.LEFT_FOOT_INDEX.value
RIGHT_FOOT_INDEX = mp_pose.PoseLandmark.RIGHT_FOOT_INDEX.value
LEFT_HAND_INDEX = mp_pose.PoseLandmark.LEFT_INDEX.value
RIGHT_HAND_INDEX = mp_pose.PoseLandmark.RIGHT_INDEX.value

# Process each frame
for frame_path in os.listdir(output_dir):
    frame = cv2.imread(os.path.join(output_dir, frame_path))
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(frame_rgb)

    # Extract keypoints if detected
    if result.pose_landmarks:
        keypoints = []
        for landmark in result.pose_landmarks.landmark:
            # Append (x, y) coordinates of each landmark
            keypoints.append((landmark.x, landmark.y))
        all_keypoints.append(keypoints)  # Store keypoints of the frame

        # Draw the pose landmarks on the frame
        mp_drawing.draw_landmarks(frame, result.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        # Display the frame with landmarks
        cv2_imshow(frame)

# Calculate movements for left foot, right foot, left hand, and right hand
left_foot_movements = []
right_foot_movements = []
left_hand_movements = []
right_hand_movements = []

if len(all_keypoints) > 1:  # Ensure there are at least two frames
    for i in range(1, len(all_keypoints)):
        # Left foot movement
        kp_prev_left_foot = np.array(all_keypoints[i-1][LEFT_FOOT_INDEX])
        kp_curr_left_foot = np.array(all_keypoints[i][LEFT_FOOT_INDEX])
        movement_left_foot = np.linalg.norm(kp_curr_left_foot - kp_prev_left_foot)
        left_foot_movements.append(movement_left_foot)

        # Right foot movement
        kp_prev_right_foot = np.array(all_keypoints[i-1][RIGHT_FOOT_INDEX])
        kp_curr_right_foot = np.array(all_keypoints[i][RIGHT_FOOT_INDEX])
        movement_right_foot = np.linalg.norm(kp_curr_right_foot - kp_prev_right_foot)
        right_foot_movements.append(movement_right_foot)

        # Left hand movement
        kp_prev_left_hand = np.array(all_keypoints[i-1][LEFT_HAND_INDEX])
        kp_curr_left_hand = np.array(all_keypoints[i][LEFT_HAND_INDEX])
        movement_left_hand = np.linalg.norm(kp_curr_left_hand - kp_prev_left_hand)
        left_hand_movements.append(movement_left_hand)

        # Right hand movement
        kp_prev_right_hand = np.array(all_keypoints[i-1][RIGHT_HAND_INDEX])
        kp_curr_right_hand = np.array(all_keypoints[i][RIGHT_HAND_INDEX])
        movement_right_hand = np.linalg.norm(kp_curr_right_hand - kp_prev_right_hand)
        right_hand_movements.append(movement_right_hand)

# Plot the movements
plt.figure(figsize=(12, 8))

plt.subplot(2, 2, 1)
plt.plot(left_foot_movements, label='Left Foot', color='b')
plt.title("Left Foot Movements")
plt.xlabel("Frame")
plt.ylabel("Movement (Euclidean Distance)")
plt.legend()

plt.subplot(2, 2, 2)
plt.plot(right_foot_movements, label='Right Foot', color='g')
plt.title("Right Foot Movements")
plt.xlabel("Frame")
plt.ylabel("Movement (Euclidean Distance)")
plt.legend()

plt.subplot(2, 2, 3)
plt.plot(left_hand_movements, label='Left Hand', color='r')
plt.title("Left Hand Movements")
plt.xlabel("Frame")
plt.ylabel("Movement (Euclidean Distance)")
plt.legend()

plt.subplot(2, 2, 4)
plt.plot(right_hand_movements, label='Right Hand', color='m')
plt.title("Right Hand Movements")
plt.xlabel("Frame")
plt.ylabel("Movement (Euclidean Distance)")
plt.legend()

plt.tight_layout()
plt.show()

# Calculate statistical features
def calculate_stats(movements):
    if movements:
        mean_val = np.mean(movements)
        max_val = np.max(movements)
        std_dev = np.std(movements)
        return mean_val, max_val, std_dev
    else:
        return None, None, None

# Get stats for each movement type
left_foot_stats = calculate_stats(left_foot_movements)
right_foot_stats = calculate_stats(right_foot_movements)
left_hand_stats = calculate_stats(left_hand_movements)
right_hand_stats = calculate_stats(right_hand_movements)

# Display statistical features
print("Left Foot Movement Stats: Mean =", left_foot_stats[0], ", Max =", left_foot_stats[1], ", Std Dev =", left_foot_stats[2])
print("Right Foot Movement Stats: Mean =", right_foot_stats[0], ", Max =", right_foot_stats[1], ", Std Dev =", right_foot_stats[2])
print("Left Hand Movement Stats: Mean =", left_hand_stats[0], ", Max =", left_hand_stats[1], ", Std Dev =", left_hand_stats[2])
print("Right Hand Movement Stats: Mean =", right_hand_stats[0], ", Max =", right_hand_stats[1], ", Std Dev =", right_hand_stats[2])

"""#4 videos comparison"""

import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
import mediapipe as mp
from scipy.spatial import distance

def load_frames_from_folder(folder_path):
    # List all image files in the folder and load them
    frame_files = sorted([os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.jpg') or f.endswith('.png')])
    frames = [cv2.imread(f) for f in frame_files]
    return frames

# Paths to the extracted frame folders for each video
video_folders = {
    '/content/drive/MyDrive/BTP/1sec.mp4': '/content/drive/MyDrive/BTP/extracted_1',
    '/content/drive/MyDrive/BTP/3sec.mp4': '/content/drive/MyDrive/BTP/extracted_3',
    '/content/drive/MyDrive/BTP/8sec.mp4': '/content/drive/MyDrive/BTP/extracted_8',
    '/content/drive/MyDrive/BTP/10sec.mp4': '/content/drive/MyDrive/BTP/extracted_10'
}

# Load frames for each video
frames_dict = {}
for video_name, folder in video_folders.items():
    frames_dict[video_name] = load_frames_from_folder(folder)

# Check the number of frames loaded for each video
for video_name, frames in frames_dict.items():
    print(f"{video_name}: {len(frames)} frames")

# Initialize MediaPipe Pose Estimator
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

def extract_keypoints_from_frame(frame):
    # Convert the image to RGB (MediaPipe expects RGB input)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    result = pose.process(rgb_frame)

    # Extract keypoints if available
    keypoints = []
    if result.pose_landmarks:
        for landmark in result.pose_landmarks.landmark:
            keypoints.append((landmark.x, landmark.y, landmark.z))  # x, y, z coordinates
    return keypoints

# Example of extracting keypoints from the first frame of the first video
frame_1_keypoints = extract_keypoints_from_frame(frames_dict['/content/drive/MyDrive/BTP/8sec.mp4'][0])
print(f"Keypoints from the first frame: {frame_1_keypoints}")

def track_movement_in_limbs(frames, video_name):
    # Dictionary to store displacement data for each limb
    movement_data = {'left_arm': [], 'right_arm': [], 'left_leg': [], 'right_leg': []}

    for i in range(1, len(frames)):
        prev_frame = frames[i-1]
        curr_frame = frames[i]

        # Extract keypoints for each frame
        prev_keypoints = extract_keypoints_from_frame(prev_frame)
        curr_keypoints = extract_keypoints_from_frame(curr_frame)

        # Ensure we have enough keypoints for limbs
        if len(prev_keypoints) >= 33 and len(curr_keypoints) >= 33:
            # Left arm keypoints: shoulder (11), elbow (13), wrist (15)
            prev_left_arm = np.array([prev_keypoints[11], prev_keypoints[13], prev_keypoints[15]])
            curr_left_arm = np.array([curr_keypoints[11], curr_keypoints[13], curr_keypoints[15]])

            # Right arm keypoints: shoulder (12), elbow (14), wrist (16)
            prev_right_arm = np.array([prev_keypoints[12], prev_keypoints[14], prev_keypoints[16]])
            curr_right_arm = np.array([curr_keypoints[12], curr_keypoints[14], curr_keypoints[16]])

            # Left leg keypoints: hip (23), knee (25), ankle (27)
            prev_left_leg = np.array([prev_keypoints[23], prev_keypoints[25], prev_keypoints[27]])
            curr_left_leg = np.array([curr_keypoints[23], curr_keypoints[25], curr_keypoints[27]])

            # Right leg keypoints: hip (24), knee (26), ankle (28)
            prev_right_leg = np.array([prev_keypoints[24], prev_keypoints[26], prev_keypoints[28]])
            curr_right_leg = np.array([curr_keypoints[24], curr_keypoints[26], curr_keypoints[28]])

            # Calculate the displacement (Euclidean distance) for each limb
            left_arm_displacement = np.linalg.norm(curr_left_arm - prev_left_arm)
            right_arm_displacement = np.linalg.norm(curr_right_arm - prev_right_arm)
            left_leg_displacement = np.linalg.norm(curr_left_leg - prev_left_leg)
            right_leg_displacement = np.linalg.norm(curr_right_leg - prev_right_leg)

            # Append the displacement to the movement data
            movement_data['left_arm'].append(left_arm_displacement)
            movement_data['right_arm'].append(right_arm_displacement)
            movement_data['left_leg'].append(left_leg_displacement)
            movement_data['right_leg'].append(right_leg_displacement)

    return movement_data

# Example: Track limb movements for 'video_1'
video_1_movements = track_movement_in_limbs(frames_dict['/content/drive/MyDrive/BTP/8sec.mp4'], "/content/drive/MyDrive/BTP/8sec.mp4")

def compute_movement_stats(movement_data):
    stats = {}
    for limb, displacements in movement_data.items():
        stats[limb] = {
            'mean': np.mean(displacements),
            'std': np.std(displacements),
            'max': np.max(displacements)
        }
    return stats

# Calculate stats for the tracked movements in 'video_1'
movement_stats_video_1 = compute_movement_stats(video_1_movements)
print("Movement Stats for Video 1:")
for limb, stats in movement_stats_video_1.items():
    print(f"{limb}: Mean={stats['mean']}, Std={stats['std']}, Max={stats['max']}")

def plot_movements_over_time(movement_data, video_name):
    plt.figure(figsize=(12, 6))

    for limb, displacements in movement_data.items():
        plt.plot(displacements, label=limb)

    plt.title(f"Movements of Limbs Over Time - {video_name}")
    plt.xlabel("Frame Number")
    plt.ylabel("Displacement (pixels)")
    plt.legend()
    plt.show()

# Plot movements for 'video_1'
plot_movements_over_time(video_1_movements, "/content/drive/MyDrive/BTP/1sec.mp4")

import mediapipe as mp
import cv2
import numpy as np

# Initialize MediaPipe Pose model
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

def extract_keypoints(video_path):
    cap = cv2.VideoCapture(video_path)
    keypoints = []  # List to store keypoints for each frame

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Convert the frame to RGB (MediaPipe expects RGB images)
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

        # Process the frame to get keypoints
        result = pose.process(frame_rgb)

        if result.pose_landmarks:
            # Extract keypoints (landmarks) from the result
            frame_keypoints = []
            for landmark in result.pose_landmarks.landmark:
                frame_keypoints.append([landmark.x, landmark.y, landmark.z])  # x, y, z coordinates
            keypoints.append(frame_keypoints)  # Append to the list of keypoints for the video

    cap.release()
    return keypoints

video_1_keypoints = extract_keypoints('/content/drive/MyDrive/BTP/1sec.mp4')  # Replace with actual path to video
video_2_keypoints = extract_keypoints('/content/drive/MyDrive/BTP/3sec.mp4')
video_3_keypoints = extract_keypoints('/content/drive/MyDrive/BTP/8sec.mp4')
video_4_keypoints = extract_keypoints('/content/drive/MyDrive/BTP/10sec.mp4')

# Now, you have video_1_keypoints, video_2_keypoints, etc., each containing keypoints for all frames

def compare_video_movements(features, video_paths):
    plt.figure(figsize=(12, 8))

    for video_path in video_paths:
        movement_data = features[video_path]
        for limb, displacements in movement_data.items():
            plt.plot(displacements, label=f'{video_path} - {limb}')

    plt.title("Comparison of Limb Movements Across Videos")
    plt.xlabel("Frames")
    plt.ylabel("Displacement (pixels)")
    plt.legend()
    plt.show()

# Assuming features dictionary holds the tracked movements for all videos
features = {}
for video_name, frames in frames_dict.items():
    video_movements = track_movement_in_limbs(frames, video_name)
    features[video_name] = video_movements

# Compare movements across all videos
compare_video_movements(features, video_folders.keys())

import matplotlib.pyplot as plt

def compare_selected_video_movements(features, video_comparisons):
    """
    Compare the movements between selected videos (e.g., 1sec vs 3sec, etc.).
    Args:
        features (dict): A dictionary containing tracked movements for each video.
        video_comparisons (list): A list of tuples, each containing two or more video names to compare.
    """
    plt.figure(figsize=(12, 8))

    for comparison in video_comparisons:
        # Iterate over the videos in the current comparison pair
        for video_path in comparison:
            movement_data = features[video_path]
            for limb, displacements in movement_data.items():
                # Plot each video movement on the same graph
                plt.plot(displacements, label=f'{video_path} - {limb}')

        # Title for each plot
        comparison_title = " vs ".join(comparison)
        plt.title(f"Comparison of Limb Movements: {comparison_title}")
        plt.xlabel("Frames")
        plt.ylabel("Displacement (pixels)")
        plt.legend()
        plt.show()


# Assuming features dictionary holds the tracked movements for all videos
features = {}
for video_name, frames in frames_dict.items():
    video_movements = track_movement_in_limbs(frames, video_name)
    features[video_name] = video_movements

# Define the video comparisons
video_comparisons = [
    ('/content/drive/MyDrive/BTP/1sec.mp4', '/content/drive/MyDrive/BTP/3sec.mp4'),  # Compare 1sec vs 3sec
    ('/content/drive/MyDrive/BTP/1sec.mp4', '/content/drive/MyDrive/BTP/8sec.mp4'),  # Compare 1sec vs 8sec
    ('/content/drive/MyDrive/BTP/1sec.mp4', '/content/drive/MyDrive/BTP/10sec.mp4'), # Compare 1sec vs 10sec
    ('/content/drive/MyDrive/BTP/3sec.mp4', '/content/drive/MyDrive/BTP/8sec.mp4', '/content/drive/MyDrive/BTP/10sec.mp4') # Compare 3sec vs 8sec vs 10sec
]

# Compare movements across the selected videos
compare_selected_video_movements(features, video_comparisons)

import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd


data = {
    "Body Part": ["Left Arm", "Right Arm", "Left Leg", "Right Leg"],
    "Excited Mean": [0.056, 0.051, 0.044, 0.049],
    "Normal Mean": [0.018, 0.020, 0.018, 0.019],
    "Excited Max": [0.256, 0.187, 0.186, 0.143],
    "Normal Max": [0.20, 0.12, 0.102, 0.103]
}

# Convert data to a DataFrame
df = pd.DataFrame(data).set_index("Body Part")

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(df, annot=True, cmap="YlGnBu", fmt=".3f", cbar=True)
plt.title("Heatmap of Movement Intensities")
plt.xlabel("Metrics")
plt.ylabel("Body Parts")
plt.show()

# import pandas as pd
# import numpy as np

# # Function to add random variation within a range
# def add_variation(base_value, variation_factor=0.1):
#     return base_value + np.random.uniform(-variation_factor, variation_factor)

# # Normal video feature range (based on your provided example)
# normal_ranges = {
#     'left_foot_mean': (0.005, 0.010),
#     'left_foot_std': (0.008, 0.010),
#     'left_foot_max': (0.060, 0.070),
#     'left_foot_min': (0.000, 0.00001),
#     'left_foot_median': (0.003, 0.005),
#     'right_foot_mean': (0.005, 0.010),
#     'right_foot_std': (0.008, 0.010),
#     'right_foot_max': (0.060, 0.070),
#     'right_foot_min': (0.000, 0.0001),
#     'right_foot_median': (0.003, 0.005)
# }

# # Excited video feature range (based on your provided example)
# excited_ranges = {
#     'left_foot_mean': (0.04, 0.05),
#     'left_foot_std': (0.03, 0.04),
#     'left_foot_max': (0.14, 0.19),
#     'left_foot_min': (0.0, 0.01),
#     'left_foot_median': (0.02, 0.03),
#     'right_foot_mean': (0.04, 0.05),
#     'right_foot_std': (0.03, 0.04),
#     'right_foot_max': (0.12, 0.14),
#     'right_foot_min': (0.0, 0.01),
#     'right_foot_median': (0.02, 0.03)
# }

# # Create dummy data for 'normal' and 'excited' videos with variation
# normal_data = []
# excited_data = []

# # Generate normal data with variation
# for _ in range(50):
#     normal_features = {
#         'left_foot_mean': add_variation(0.0079915409596620942),
#         'left_foot_std': add_variation(0.009817951123122495),
#         'left_foot_max': add_variation(0.06749545185520164),
#         'left_foot_min': add_variation(3.655009112260814e-06),
#         'left_foot_median': add_variation(0.0047999441668310171),
#         'right_foot_mean': add_variation(0.0072805542461041),
#         'right_foot_std': add_variation(0.0090505051241064578),
#         'right_foot_max': add_variation(0.06309830275326185),
#         'right_foot_min': add_variation(7.00168128254923e-05),
#         'right_foot_median': add_variation(0.0041267115827776051),
#         'label': 0  # Normal video label
#     }
#     normal_data.append(normal_features)

# # Generate excited data with variation
# for _ in range(50):
#     excited_features = {
#         'left_foot_mean': add_variation(0.04486415841347276),
#         'left_foot_std': add_variation(0.03398235630992344),
#         'left_foot_max': add_variation(0.18629766842825926),
#         'left_foot_min': add_variation(0.0),
#         'left_foot_median': add_variation(0.028),
#         'right_foot_mean': add_variation(0.049919008524262634),
#         'right_foot_std': add_variation(0.03280203886833978),
#         'right_foot_max': add_variation(0.14339467465299824),
#         'right_foot_min': add_variation(0.0),
#         'right_foot_median': add_variation(0.035),
#         'label': 1  # Excited video label
#     }
#     excited_data.append(excited_features)

# # Combine the data into a DataFrame
# data = normal_data + excited_data
# df = pd.DataFrame(data)

# # Shuffle the DataFrame
# df = df.sample(frac=1).reset_index(drop=True)

# # Split the dataset into features (X) and labels (y)
# X = df.drop(columns='label')
# y = df['label']

# # Show the dummy dataset
# print(df.head())

# # Save to CSV (optional)
# df.to_csv('dummy_dataset_with_variation.csv', index=False)